{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#CNN (A)\n",
        "\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "max_features = 10000\n",
        "maxlen = 100\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hUpFH9e_RZ1",
        "outputId": "97a55a69-bff1-4818-c49b-76f97bcc68cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 1s 0us/step\n",
            "25000 train sequences\n",
            "25000 test sequences\n",
            "Pad sequences (samples x time)\n",
            "x_train shape: (25000, 100)\n",
            "x_test shape: (25000, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN (B)\n",
        "\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
        "from keras.preprocessing import sequence\n",
        "max_features = 10000\n",
        "maxlen = 100\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128, input_length=maxlen))\n",
        "model.add(Conv1D(64, 5, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "print('Training model...')\n",
        "model.fit(x_train, y_train, epochs=3, batch_size=32, validation_split=0.2)\n",
        "print('Evaluating model...')\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fwqv2wyE_k3i",
        "outputId": "78d71ea0-5cbb-4174-966d-42630c99b45a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "25000 train sequences\n",
            "25000 test sequences\n",
            "Pad sequences (samples x time)\n",
            "x_train shape: (25000, 100)\n",
            "x_test shape: (25000, 100)\n",
            "Training model...\n",
            "Epoch 1/3\n",
            "625/625 [==============================] - 30s 47ms/step - loss: 0.4747 - accuracy: 0.7708 - val_loss: 0.3508 - val_accuracy: 0.8412\n",
            "Epoch 2/3\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 0.2576 - accuracy: 0.8953 - val_loss: 0.3365 - val_accuracy: 0.8546\n",
            "Epoch 3/3\n",
            "625/625 [==============================] - 31s 49ms/step - loss: 0.1238 - accuracy: 0.9590 - val_loss: 0.3844 - val_accuracy: 0.8496\n",
            "Evaluating model...\n",
            "Test loss: 0.3903481364250183\n",
            "Test accuracy: 0.8460400104522705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# RNN sentiment analysis on movie reviews\n",
        "\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, SimpleRNN, Embedding, Flatten\n",
        "\n",
        "# Load IMDb dataset\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)\n",
        "\n",
        "# Pad sequences\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=50)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=50)\n",
        "\n",
        "# Define model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer\n",
        "model.add(Embedding(10000, 32, input_length=50))\n",
        "\n",
        "# SimpleRNN layer\n",
        "model.add(SimpleRNN(32))\n",
        "\n",
        "# Dense layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIJlqnumA7kF",
        "outputId": "8aedce86-0390-4872-e704-fb6250ad04e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 50, 32)            320000    \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 322113 (1.23 MB)\n",
            "Trainable params: 322113 (1.23 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ADD TWO NUMBERS\n",
        "\n",
        "#Step-1: Import\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from random import randrange\n",
        "#Step-2: Generate Training Data\n",
        "trainingInput = [[i, i + randrange(5000)] for i in range(1, 5000)]\n",
        "trainingOutput = [(input [0] + input [1]) for input in trainingInput ]\n",
        "testInput = [[5, 5], [1, 9], [2, 5], [6, 3], [1, 4]]\n",
        "testOutput = [10, 10, 7, 9, 5]\n",
        "#Step-3: Build the model\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Flatten(input_shape=(2,)))\n",
        "model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "#Step-4: Compile the model\n",
        "model.compile(optimizer='adam', loss=tf.keras.losses.mae, metrics=['mae'])\n",
        "#Step-5: Training\n",
        "model.fit(trainingInput, trainingOutput, batch_size=5, epochs=3)\n",
        "#Step-6: Final Evaluation and Prediction\n",
        "test_loss, test_acc = model.evaluate(testInput, testOutput)\n",
        "print(\"Test Accuracy : \", test_acc)\n",
        "a = np.array([[3, 3000], [4, 5], [1,10], [2,10],[5,9], [4,10], [1,15]])\n",
        "print(model.predict(a))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOEHuK8VBdLK",
        "outputId": "f4c688e3-e7c6-41fe-c756-07e2c96c8ca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1000/1000 [==============================] - 5s 4ms/step - loss: 241.3566 - mae: 241.3566\n",
            "Epoch 2/3\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 28.6675 - mae: 28.6675\n",
            "Epoch 3/3\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 28.5529 - mae: 28.5529\n",
            "1/1 [==============================] - 1s 581ms/step - loss: 0.2576 - mae: 0.2576\n",
            "Test Accuracy :  0.25757989287376404\n",
            "1/1 [==============================] - 0s 175ms/step\n",
            "[[3010.5828  ]\n",
            " [   9.251566]\n",
            " [  11.226904]\n",
            " [  12.218241]\n",
            " [  14.256031]\n",
            " [  14.250777]\n",
            " [  16.240612]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ANN\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "iris =datasets.load_iris()\n",
        "X, y = datasets.load_iris( return_X_y = True)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40)# Define the network model and its arguments.\n",
        "# Set the number of neurons/nodes for each layer:\n",
        "model = Sequential()\n",
        "model.add(Dense(2,input_shape=(4,)))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "#sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "#model.compile(loss='categorical_crossentropy', optimizer=sgd,\n",
        "metrics=['accuracy']# Compile the model and calculate its accuracy:\n",
        "model.compile(loss='mean_squared_error', optimizer='sgd',metrics=['accuracy']) #model.fit(X_train, y_train, batch_size=32,epochs=3)\n",
        "# Print a summary of the Keras model:\n",
        "model.summary()\n",
        "#model.fit(X_train, y_train)\n",
        "#model.fit(X_train, y_train,batch_size=32, epochs=3)\n",
        "model.fit(X_train, y_train, epochs=5)\n",
        "score = model.evaluate(X_test, y_test)\n",
        "print(score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tq5f2dCrDbHD",
        "outputId": "73dfb1e9-8593-488c-cad3-2a44da76287a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 2)                 10        \n",
            "                                                                 \n",
            " activation (Activation)     (None, 2)                 0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13 (52.00 Byte)\n",
            "Trainable params: 13 (52.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 1s 6ms/step - loss: 0.6789 - accuracy: 0.3333\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.6782 - accuracy: 0.3333\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.6775 - accuracy: 0.3333\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.6769 - accuracy: 0.3333\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.6762 - accuracy: 0.3333\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7190 - accuracy: 0.3333\n",
            "[0.7189559936523438, 0.3333333432674408]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#X-OR GATE\n",
        "\n",
        "# importing Python library\n",
        "import numpy as np\n",
        "\n",
        "# define Unit Step Function\n",
        "def unitStep(v):\n",
        "\tif v >= 0:\n",
        "\t\treturn 1\n",
        "\telse:\n",
        "\t\treturn 0\n",
        "\n",
        "# design Perceptron Model\n",
        "def perceptronModel(x, w, b):\n",
        "\tv = np.dot(w, x) + b\n",
        "\ty = unitStep(v)\n",
        "\treturn y\n",
        "\n",
        "# NOT Logic Function\n",
        "# wNOT = -1, bNOT = 0.5\n",
        "def NOT_logicFunction(x):\n",
        "\twNOT = -1\n",
        "\tbNOT = 0.5\n",
        "\treturn perceptronModel(x, wNOT, bNOT)\n",
        "\n",
        "# AND Logic Function\n",
        "# here w1 = wAND1 = 1,\n",
        "# w2 = wAND2 = 1, bAND = -1.5\n",
        "def AND_logicFunction(x):\n",
        "\tw = np.array([1, 1])\n",
        "\tbAND = -1.5\n",
        "\treturn perceptronModel(x, w, bAND)\n",
        "\n",
        "# OR Logic Function\n",
        "# w1 = 1, w2 = 1, bOR = -0.5\n",
        "def OR_logicFunction(x):\n",
        "\tw = np.array([1, 1])\n",
        "\tbOR = -0.5\n",
        "\treturn perceptronModel(x, w, bOR)\n",
        "\n",
        "# XOR Logic Function\n",
        "# with AND, OR and NOT\n",
        "# function calls in sequence\n",
        "def XOR_logicFunction(x):\n",
        "\ty1 = AND_logicFunction(x)\n",
        "\ty2 = OR_logicFunction(x)\n",
        "\ty3 = NOT_logicFunction(y1)\n",
        "\tfinal_x = np.array([y2, y3])\n",
        "\tfinalOutput = AND_logicFunction(final_x)\n",
        "\treturn finalOutput\n",
        "\n",
        "# testing the Perceptron Model\n",
        "test1 = np.array([0, 1])\n",
        "test2 = np.array([1, 1])\n",
        "test3 = np.array([0, 0])\n",
        "test4 = np.array([1, 0])\n",
        "\n",
        "print(\"XOR({}, {}) = {}\".format(0, 1, XOR_logicFunction(test1)))\n",
        "print(\"XOR({}, {}) = {}\".format(1, 1, XOR_logicFunction(test2)))\n",
        "print(\"XOR({}, {}) = {}\".format(0, 0, XOR_logicFunction(test3)))\n",
        "print(\"XOR({}, {}) = {}\".format(1, 0, XOR_logicFunction(test4)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "z5JD54w9OV6J",
        "outputId": "eee3bde9-19fd-4366-f38f-5c4f50275f62"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XOR(0, 1) = 1\n",
            "XOR(1, 1) = 0\n",
            "XOR(0, 0) = 0\n",
            "XOR(1, 0) = 1\n"
          ]
        }
      ]
    }
  ]
}